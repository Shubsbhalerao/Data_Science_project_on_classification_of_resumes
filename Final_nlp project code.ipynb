{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "import os,re\n",
    "import docx2txt\n",
    "import textract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(r\"C:\\Users\\bhale\\project 2 NLP\\Resumes\\Resumes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc5ff6",
   "metadata": {},
   "source": [
    "# JS Developer .docx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2329d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_1 = []\n",
    "category_1 = []\n",
    "directory = r\"C:\\Users\\bhale\\project 2 NLP\\Resumes\\Resumes\\JS Developer\"\n",
    "for i in os.listdir(directory):\n",
    "    if i.endswith('.docx') or i.endswith('.doc') or i.endswith('.pdf'):\n",
    "        os.path.join(directory, i)\n",
    "    file_path_1.append((textract.process(os.path.join(directory, i))).decode('utf-8'))\n",
    "    category_1.append('React JS Developer Resume')\n",
    "file_path_1, category_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08dd98",
   "metadata": {},
   "source": [
    "# People Soft Resume .docx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_2 = []\n",
    "category_2 = []\n",
    "directory_1 = r\"C:\\Users\\bhale\\project 2 NLP\\Resumes\\Resumes\\Peoplesoft_Resumes\"\n",
    "for i in os.listdir(directory_1):\n",
    "    if i.endswith('.docx') or i.endswith('.doc') or i.endswith('.pdf'):\n",
    "        os.path.join(directory_1, i)\n",
    "    file_path_2.append((textract.process(os.path.join(directory_1, i))).decode('utf-8'))\n",
    "    category_2.append('PeopleSoft resume')\n",
    "file_path_2,category_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0884136",
   "metadata": {},
   "source": [
    "# SQL Developer Lightening insight Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c22b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_3 = []\n",
    "category_3 = []\n",
    "directory_2 = r\"C:\\Users\\bhale\\project 2 NLP\\Resumes\\Resumes\\SQL Developer Lightning insight\"\n",
    "for i in os.listdir(directory_2):\n",
    "    if i.endswith('.docx') or i.endswith('.doc') or i.endswith('.pdf'):\n",
    "        os.path.join(directory_2, i)\n",
    "    file_path_3.append((textract.process(os.path.join(directory_2, i))).decode('utf-8'))\n",
    "    category_3.append('SQL Developer Lightning insight')\n",
    "file_path_3,category_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be353977",
   "metadata": {},
   "source": [
    "# WOrkday Resume .docx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_4=[]\n",
    "category_4=[]\n",
    "directory_3=r\"C:\\Users\\bhale\\project 2 NLP\\Resumes\\Resumes\\workday resumes\"\n",
    "for i in os.listdir(directory_3):\n",
    "    if i.endswith('.docx') or i.endswith('.doc') or i.endswith('.pdf'):\n",
    "        os.path.join(directory_3,i)\n",
    "    file_path_4.append((textract.process(os.path.join(directory_3,i))).decode('utf-8'))\n",
    "    category_4.append('Workday Resumes')\n",
    "file_path_4,category_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9712da9b",
   "metadata": {},
   "source": [
    "# Creating dataframe for React JS Developer Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a16356",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_js=pd.DataFrame(data=file_path_1,columns=['CV'])\n",
    "react_js['Category_1']=category_1\n",
    "react_js"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30089dce",
   "metadata": {},
   "source": [
    "# For Peoplesoft Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peoplesoft = pd.DataFrame(data = file_path_2 , columns = ['CV'])\n",
    "peoplesoft['category_2'] = category_2\n",
    "peoplesoft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d2d17a",
   "metadata": {},
   "source": [
    "# For SQL Developer Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqldev = pd.DataFrame(data = file_path_3 , columns = ['CV'])\n",
    "sqldev['category_3'] = category_3\n",
    "sqldev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf035add",
   "metadata": {},
   "source": [
    "# Workday Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdays = pd.DataFrame(data = file_path_4 , columns = ['CV'])\n",
    "workdays['category_4'] = category_4\n",
    "workdays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb25a42",
   "metadata": {},
   "source": [
    "# All other Resumes added into the react js datafrme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_resumes=[peoplesoft,sqldev,workdays]\n",
    "data=react_js.append(all_resumes,ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255e46b",
   "metadata": {},
   "source": [
    "# Taking all categories of resume into a single column and Removing the sub category columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da5b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Category']=category_1+category_2+category_3+category_4\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fede769",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Category_1', 'category_2', 'category_3','category_4'], axis = 1, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229cde3",
   "metadata": {},
   "source": [
    "# So we have to convert data into csv format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede46192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Resume_classification_NLP_project.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d30aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume=pd.read_csv('Resume_classification_NLP_project.csv')\n",
    "resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423f453",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f99ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5b7e3",
   "metadata": {},
   "source": [
    "## Calculating each characteristics in dataframe before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_char=resume['CV'].apply(len)\n",
    "before_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e41f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of characters before cleaning dataset :',before_char.sum())\n",
    "print('Mean of each characters before cleaning the dataset:',before_char.mean())\n",
    "print('Median of characters before cleaning the dataset:',before_char.median())\n",
    "print('Standard Deviation of characters before cleaning the dataset:',before_char.std())\n",
    "print('skew of characters before cleaning the dataset:',before_char.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4bbd7",
   "metadata": {},
   "source": [
    "## Calculating each word characteristics in dataframe before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_words=resume['CV'].apply(lambda x:len(str(x).split(' ')))\n",
    "before_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of Word in dataset before cleaning:',before_words.sum())\n",
    "print('Mean of each Word in dataset before cleaning:',before_words.mean())\n",
    "print('Median of Word in dataset before cleaning:',before_words.median())\n",
    "print('Standard Deviation of Word in dataset before cleaning:',before_words.std())\n",
    "print('skew of Word dataset before cleaning:',before_words.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ab25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9600963",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb71c83c",
   "metadata": {},
   "source": [
    "# Checking for no.of resumes in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae49c0e",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "resume['Category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1195c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "resume['Category'].value_counts().plot.pie(autopct='%.2f%%',explode = [0,0,0,0.3],colors=['r','b','g','y']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d68cc",
   "metadata": {},
   "source": [
    "#### We observe that 30.38% of the dataset is occupied by React JS Developer, proceeding with Workday Resume of 26.58% , PeopleSoft Resume of 25.32% of the dataset and SQL Developer of 17.72% in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autoviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad366f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoviz import AutoViz_Class\n",
    "AV=AutoViz_Class()\n",
    "df=AV.AutoViz('Resume_classification_NLP_project.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"Resume_classification_NLP_project.csv\"\n",
    "sep=','\n",
    "dft=AV.AutoViz(\n",
    "filename,\n",
    "sep=',',\n",
    "depVar=\"\",\n",
    "dfte=None,\n",
    "header=0,\n",
    "verbose=0,\n",
    "lowess=False,\n",
    "chart_format=\"svg\",\n",
    "max_rows_analyzed=15000,\n",
    "max_cols_analyzed=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331028a",
   "metadata": {},
   "source": [
    "### Because of no numeric and integer vars in data. it does not show any visualization for above file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "advert_report=sv.analyze(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b6ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the report \n",
    "advert_report.show_html('Advertising.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.HTML('Advertising.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c4928",
   "metadata": {},
   "source": [
    "## EDA part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f7436",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffa590",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645bb5e",
   "metadata": {},
   "source": [
    "#### We will perform label encoding to convert category variable from string datatype to float datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "resume[\"Encoded_Skill\"] = le.fit_transform(resume[\"Category\"])\n",
    "resume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc0300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frequency of each species after label encoding\n",
    "resume['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Displaying the distinct categories of resume -\")\n",
    "print(resume.Category.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57cf64",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Regular Expression\n",
    "import string\n",
    "def data_cleaning(CV):\n",
    "    '''Make text lowercase, remove text in square brackets,remove punctuatuation and remove words containing numbers'''\n",
    "    CV=CV.lower()\n",
    "    CV=re.sub('\\[.*?\\]', '', CV)\n",
    "    CV=re.sub('[%s]' % re.escape(string.punctuation), '',CV)\n",
    "    CV=re.sub('\\w*\\d\\w*', '', CV)\n",
    "    CV=re.sub(\"[0-9\" \"]+\",\" \",CV)\n",
    "    CV=re.sub('[‘’“”…]', '', CV)\n",
    "    CV=re.sub('\\n', '', CV)\n",
    "   # CV=re.sub('\\t', '', CV)\n",
    "    return CV\n",
    "clean = lambda x:data_cleaning(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78dfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['CV']=resume.CV.apply(clean)\n",
    "resume.CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129979ac",
   "metadata": {},
   "source": [
    "## Word frequency BEFORE removal of STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Frequency\n",
    "frequency = pd.Series(' '.join(resume['CV']).split()).value_counts()[:20] #For top 20\n",
    "frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c41c843",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66917d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume['CV']=resume['CV'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d296a8d",
   "metadata": {},
   "source": [
    "## Word frequency after removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c913ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 Word frequency after removal of stopwords\n",
    "frequency_ASW=pd.Series(' '.join(resume['CV']).split()).value_counts()[:20]\n",
    "frequency_ASW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "import docx\n",
    "import spacy\n",
    "from spacy import schemas\n",
    "from spacy import Dict\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb870d",
   "metadata": {},
   "source": [
    "## Performing a NER(Name Entity Recognition)(Using spacy library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "text=nlp(resume[\"CV\"][0])\n",
    "displacy.render(text,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64b5e1",
   "metadata": {},
   "source": [
    "### First take a look at the number of Characters present in each sentence. This can give us a rough idea about the resume length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3e07d6",
   "metadata": {},
   "source": [
    "### Calculating each Characterstic in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd47782",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters=resume[\"CV\"].apply(len)\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4450e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of characters dataset:',characters.sum())\n",
    "print('Mean of each characters in datset:',characters.mean())\n",
    "print('Median of characters in dataset:',characters.median())\n",
    "print('Standard Deviation of characters in dataset:',characters.std())\n",
    "print('skew of characters dataset:',characters.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727add64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.distplot(x = characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e3196",
   "metadata": {},
   "source": [
    "#### Calculating each Word Characterstic in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = resume['CV'].apply(lambda x: len(str(x).split(' ')))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Number of Word in dataset:',words.sum())\n",
    "print('Mean of each Word in datset:',words.mean())\n",
    "print('Median of Word in dataset:',words.median())\n",
    "print('Standard Deviation of Word in dataset:',words.std())\n",
    "print('skew of Word dataset:',words.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(x = words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bd4dd",
   "metadata": {},
   "source": [
    "### Visualization of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1531e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"The distinct categories of resumes\")\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(y=\"Category\", data=resume,palette=(\"Set2\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197746fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordBarGraphFunction_1(df,column,title):\n",
    "    topic_words = [ z.lower() for y in\n",
    "                       [ x.split() for x in df[column] if isinstance(x, str)]\n",
    "                       for z in y]\n",
    "    word_count_dict = dict(Counter(topic_words))\n",
    "    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n",
    "    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.barplot(x=np.arange(20),y= [word_count_dict[w] for w in reversed(popular_words_nonstop[0:20])])\n",
    "    plt.xticks([x + 0.5 for x in range(20)], reversed(popular_words_nonstop[0:20]),rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "wordBarGraphFunction_1(resume,'CV','Most frequent words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6cab2e",
   "metadata": {},
   "source": [
    "# Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e093c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEnerate wordcloud\n",
    "plt.figure(figsize=(30,30),dpi=300)\n",
    "wordcloud=WordCloud().generate(str(resume))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386d4a9",
   "metadata": {},
   "source": [
    "### Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d24450",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\n",
    "for i in range(0,len(resume)):\n",
    "    corpus=corpus+resume['CV'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "tokens=tokenizer.tokenize(corpus)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fe805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for uniformity convert whole text into lower case words\n",
    "words=[]\n",
    "for word in tokens:\n",
    "    words.append(word.lower())\n",
    "words[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223db15f",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b19aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(str(resume))\n",
    "ps=PorterStemmer()\n",
    "for w in words:\n",
    "    rootwords=ps.stem(w)\n",
    "    print(rootwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826df7f",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55706656",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd75143",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d16d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the example of standard form of a word\n",
    "print(lemmas.lemmatize('watches'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fa84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization is used for all text data in resume \n",
    "print(lemmas.lemmatize(str(resume)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa411782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenization using spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(str(resume))\n",
    "tokens = [token.text for token in doc]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a04893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the tokens to their root form\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d99232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the vaocabulary\n",
    "pd.DataFrame(cv.vocabulary_, index=[0]).T.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a52ac",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db608ca",
   "metadata": {},
   "source": [
    "### count vectorizer tells the frequency of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaac2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredText = resume[\"CV\"]\n",
    "requiredTarget = resume[\"Encoded_Skill\"].values\n",
    "Countvectorizer=CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',stop_words = 'english')\n",
    "bag = Countvectorizer.fit_transform(requiredText)\n",
    "Countvectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e456b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df = 1, max_df = 0.9)\n",
    "count_vect = vectorizer1.fit_transform(resume[\"CV\"])\n",
    "word_freq_df = pd.DataFrame({'term': vectorizer1.get_feature_names(), 'occurrences':np.asarray(count_vect.sum(axis=0)).ravel().tolist()})\n",
    "word_freq_df['frequency'] = word_freq_df['occurrences']/np.sum(word_freq_df['occurrences'])\n",
    "word_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(x =[word_freq_df['frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97755db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(sublinear_tf=True, stop_words='english',max_features=1500)\n",
    "word_vectorizer.fit(requiredText)\n",
    "WordFeatures = word_vectorizer.transform(requiredText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f339655",
   "metadata": {},
   "source": [
    "# Model Building || Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(WordFeatures,requiredTarget,random_state=3,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X train shape:\",x_train.shape)\n",
    "print(\"X test shape:\",x_test.shape)\n",
    "print(\"y train shape:\",y_train.shape)\n",
    "print(\"y test shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298225c",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,accuracy_score,precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on a dataset\n",
    "pred_train_log=log_reg.predict(x_train)\n",
    "pred_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on train data\n",
    "acc_train_log=np.mean(pred_train_log==y_train)\n",
    "print('Accuracy of train data in logistic regression:',acc_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d638ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test data\n",
    "pred_test_log=log_reg.predict(x_test)\n",
    "pred_test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3869561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on a test dataset \n",
    "acc_test_log=np.mean(pred_test_log==y_test)\n",
    "print('Accuracy of test data in logistic regression:',acc_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "log_c_matrix=confusion_matrix(y_test,pred_test_log)\n",
    "log_c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print('Classification report of logistic regression:',classification_report(y_test,pred_test_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log = round(accuracy_score(y_test,pred_test_log),4)\n",
    "precision_log = round(precision_score(y_test,pred_test_log,average = 'macro'),4)\n",
    "recall_log = round(recall_score(y_test,pred_test_log,average = 'macro'),4)\n",
    "f1_log = round(f1_score(y_test,pred_test_log,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_log )\n",
    "print('Precision Score  : ',precision_log )\n",
    "print('Recall Score     : ', recall_log)\n",
    "print('f1-Score         : ',f1_log )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036fb465",
   "metadata": {},
   "source": [
    "# 2. DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7039456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e567f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT_classifier = DecisionTreeClassifier(criterion = 'entropy', max_depth=2)\n",
    "DT_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_dt = DT_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "acc_train_dt = np.mean(pred_train_dt==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN DECISION TREE:\",acc_train_dt )\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_dt = DT_classifier.predict(x_test)\n",
    "#Accuracy on Test Data\n",
    "acc_test_dt = np.mean(pred_test_dt==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN DECISION TREE:\",acc_test_dt )\n",
    "\n",
    "#Confusion Matrix\n",
    "dt_cmatrix = confusion_matrix(y_test,pred_test_dt)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF DECISION TREE:\\n\", classification_report(y_test,pred_test_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84530118",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dt = round(accuracy_score(y_test,pred_test_dt),4)\n",
    "precision_dt = round(precision_score(y_test,pred_test_dt,average = 'macro'),4)\n",
    "recall_dt = round(recall_score(y_test,pred_test_dt,average = 'macro'),4)\n",
    "f1_dt = round(f1_score(y_test,pred_test_dt,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_dt )\n",
    "print('Precision Score  : ',precision_dt )\n",
    "print('Recall Score     : ', recall_dt)\n",
    "print('f1-Score         : ',f1_dt )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0459fe",
   "metadata": {},
   "source": [
    "# 3.RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necesssary library\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeadd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = {'n_estimators':15,'class_weight': \"balanced\",'n_jobs':-1,'random_state':3}\n",
    "RF_classifier = RandomForestClassifier(**RF)\n",
    "RF_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_rf = RF_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "acc_train_rf = np.mean(pred_train_rf==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN RANDOM FOREST:\",acc_train_rf)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_rf = RF_classifier.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "acc_test_rf = np.mean(pred_test_rf==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN RANDOM FOREST:\",acc_test_rf )\n",
    "\n",
    "#Confusion Matrix\n",
    "rf_cm = confusion_matrix(y_test,pred_test_rf)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF RANDOM FOREST:\\n\", classification_report(y_test,pred_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2cef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf = round(accuracy_score(y_test,pred_test_rf),4)\n",
    "precision_rf = round(precision_score(y_test,pred_test_rf,average = 'macro'),4)\n",
    "recall_rf = round(recall_score(y_test,pred_test_rf,average = 'macro'),4)\n",
    "f1_rf = round(f1_score(y_test,pred_test_rf,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_rf )\n",
    "print('Precision Score  : ',precision_rf )\n",
    "print('Recall Score     : ', recall_rf)\n",
    "print('f1-Score         : ',f1_rf )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beae75a",
   "metadata": {},
   "source": [
    "# 4. SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272dd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessar library for svm\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2168e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = (SVC(kernel='linear'))\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting On Train Data\n",
    "pred_train_svm = svm_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_svm = np.mean(pred_train_svm==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN SUPPORT VECTOR MACHINE:\",train_acc_svm )\n",
    "\n",
    "#Prediciting On Test Data\n",
    "pred_test_svm = svm_classifier.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "test_acc_svm = np.mean(pred_test_svm==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN SUPPORT VECTOR MACHINE:\",test_acc_svm)\n",
    "\n",
    "#Confusion Matrix\n",
    "svm_cm = confusion_matrix(y_test,pred_test_svm)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF SUPPORT VECTOR MACHINE:\\n\", classification_report(y_test,pred_test_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fd3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_svm = round(accuracy_score(y_test,pred_test_svm),4)\n",
    "precision_svm = round(precision_score(y_test,pred_test_svm,average = 'macro'),4)\n",
    "recall_svm = round(recall_score(y_test,pred_test_svm,average = 'macro'),4)\n",
    "f1_svm = round(f1_score(y_test,pred_test_svm,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_svm )\n",
    "print('Precision Score  : ',precision_svm )\n",
    "print('Recall Score     : ', recall_svm)\n",
    "print('f1-Score         : ',f1_svm )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665e1e5",
   "metadata": {},
   "source": [
    "# 5. MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4145de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  importing the library\n",
    "from sklearn.naive_bayes import MultinomialNB as MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_mb = MB()\n",
    "classifier_mb.fit(x_train,y_train)\n",
    "\n",
    "#Predicting On Train Data\n",
    "pred_train_mb = classifier_mb.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "train_acc_mb = np.mean(pred_train_mb==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN MULTINOMIAL NAVIE BAYES:\", train_acc_mb)\n",
    "\n",
    "#Predicting On Test Data\n",
    "pred_test_mb = classifier_mb.predict(x_test)\n",
    "#Accuracy On Test Data\n",
    "test_acc_mb = np.mean(pred_test_mb==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN MULTINOMIAL NAVIE BAYES:\", test_acc_mb)\n",
    "\n",
    "#Confusion Matrix\n",
    "mb_cm = confusion_matrix(y_test,pred_test_mb)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF MULTINOMIAL NAVIE BAYES:\\n\", classification_report(y_test,pred_test_mb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mb = round(accuracy_score(y_test,pred_test_mb),4)\n",
    "precision_mb = round(precision_score(y_test,pred_test_mb,average = 'macro'),4)\n",
    "recall_mb = round(recall_score(y_test,pred_test_mb,average = 'macro'),4)\n",
    "f1_mb = round(f1_score(y_test,pred_test_mb,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_mb )\n",
    "print('Precision Score  : ',precision_mb )\n",
    "print('Recall Score     : ', recall_mb)\n",
    "print('f1-Score         : ',f1_mb )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1db66",
   "metadata": {},
   "source": [
    "## 6. ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e001b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_classifier = AdaBoostClassifier()\n",
    "adaboost_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_ab = adaboost_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "acc_train_ab = np.mean(pred_train_ab==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN ADABOOST:\",acc_train_ab)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_ab = adaboost_classifier.predict(x_test)\n",
    "#Accuracy on Test Data\n",
    "acc_test_ab = np.mean(pred_test_ab==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN ADABOOSt:\",acc_test_ab )\n",
    "\n",
    "#Confusion Matrix\n",
    "adaboost_cmatrix = confusion_matrix(y_test,pred_test_ab)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF ADABOOST CLASSIFIER:\\n\", classification_report(y_test,pred_test_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ab = round(accuracy_score(y_test,pred_test_ab),4)\n",
    "precision_ab = round(precision_score(y_test,pred_test_ab,average = 'macro'),4)\n",
    "recall_ab = round(recall_score(y_test,pred_test_ab,average = 'macro'),4)\n",
    "f1_ab = round(f1_score(y_test,pred_test_ab,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_ab )\n",
    "print('Precision Score  : ',precision_ab )\n",
    "print('Recall Score     : ', recall_ab)\n",
    "print('f1-Score         : ',f1_ab )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca640e6",
   "metadata": {},
   "source": [
    "## 7. GRADIENTBOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af30c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier()\n",
    "gb_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_gb = gb_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "acc_train_gb = np.mean(pred_train_gb==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN GRADIENTBOOST:\",acc_train_gb)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_gb = gb_classifier.predict(x_test)\n",
    "#Accuracy on Test Data\n",
    "acc_test_gb = np.mean(pred_test_gb==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN GRADIENTBOOST CLASSIFIER:\",acc_test_gb )\n",
    "\n",
    "#Confusion Matrix\n",
    "gradientboost_cmatrix = confusion_matrix(y_test,pred_test_gb)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF GRADIENTBOOST CLASSIFIER:\\n\", classification_report(y_test,pred_test_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed06b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb= round(accuracy_score(y_test,pred_test_gb),4)\n",
    "precision_gb = round(precision_score(y_test,pred_test_gb,average = 'macro'),4)\n",
    "recall_gb = round(recall_score(y_test,pred_test_gb,average = 'macro'),4)\n",
    "f1_gb = round(f1_score(y_test,pred_test_gb,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_gb )\n",
    "print('Precision Score  : ',precision_gb )\n",
    "print('Recall Score     : ', recall_gb)\n",
    "print('f1-Score         : ',f1_gb )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23acca05",
   "metadata": {},
   "source": [
    "## 8.XGBCLASSIFIER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b06fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d02958",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_classifier = XGBClassifier()\n",
    "xg_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_xg = xg_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "acc_train_xg = np.mean(pred_train_xg==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN XGBCLASSIFIER:\",acc_train_xg)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_xg = xg_classifier.predict(x_test)\n",
    "#Accuracy on Test Data\n",
    "acc_test_xg = np.mean(pred_test_xg==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN XGB CLASSIFIER:\",acc_test_xg )\n",
    "\n",
    "#Confusion Matrix\n",
    "xgb_cmatrix = confusion_matrix(y_test,pred_test_xg)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF XGB CLASSIFIER:\\n\", classification_report(y_test,pred_test_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_xg= round(accuracy_score(y_test,pred_test_xg),4)\n",
    "precision_xg = round(precision_score(y_test,pred_test_xg,average = 'macro'),4)\n",
    "recall_xg = round(recall_score(y_test,pred_test_xg,average = 'macro'),4)\n",
    "f1_xg = round(f1_score(y_test,pred_test_xg,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_xg )\n",
    "print('Precision Score  : ',precision_xg )\n",
    "print('Recall Score     : ', recall_xg)\n",
    "print('f1-Score         : ',f1_xg )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22f149",
   "metadata": {},
   "source": [
    "## 9.LGBM CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_classifier = LGBMClassifier()\n",
    "lgbm_classifier.fit(x_train,y_train)\n",
    "\n",
    "#Predicting on Train Data\n",
    "pred_train_lgbm = lgbm_classifier.predict(x_train)\n",
    "#Accuracy On Train Data\n",
    "acc_train_lgbm = np.mean(pred_train_lgbm==y_train)\n",
    "print(\"ACCURACY OF TRAIN DATA IN LGBMCLASSIFIER:\",acc_train_lgbm)\n",
    "\n",
    "#Predicting on Test Data\n",
    "pred_test_lgbm = lgbm_classifier.predict(x_test)\n",
    "#Accuracy on Test Data\n",
    "acc_test_lgbm = np.mean(pred_test_lgbm==y_test)\n",
    "print(\"ACCURACY OF TEST DATA IN LGBM CLASSIFIER:\",acc_test_lgbm )\n",
    "\n",
    "#Confusion Matrix\n",
    "lgbm_cmatrix = confusion_matrix(y_test,pred_test_lgbm)\n",
    "\n",
    "#Classification Report\n",
    "print(\"CLASSIFICATION REPORT OF LGBM CLASSIFIER:\\n\", classification_report(y_test,pred_test_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lgbm= round(accuracy_score(y_test,pred_test_lgbm),4)\n",
    "precision_lgbm = round(precision_score(y_test,pred_test_lgbm,average = 'macro'),4)\n",
    "recall_lgbm = round(recall_score(y_test,pred_test_lgbm,average = 'macro'),4)\n",
    "f1_lgbm = round(f1_score(y_test,pred_test_lgbm,average = 'macro'),4)\n",
    "\n",
    "#Printing Accuracy, Recall, precision, F1_score\n",
    "print('Accuracy Score   : ',accuracy_lgbm)\n",
    "print('Precision Score  : ',precision_lgbm )\n",
    "print('Recall Score     : ', recall_lgbm)\n",
    "print('f1-Score         : ',f1_lgbm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd74459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2841b76e",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,24))\n",
    "\n",
    "plt.suptitle(\"Confusion Matrixes\", fontsize=24)\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "plt.title(\"LOGISTIC REGRESSION\")\n",
    "sns.heatmap(log_c_matrix, cbar=False, annot=True, cmap=\"mako\",  fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "plt.title(\"DECISION TREE\")\n",
    "sns.heatmap(dt_cmatrix, cbar=False, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "plt.title(\"RANDOM FOREST CLASSIFICATION\")\n",
    "sns.heatmap(rf_cm, cbar=False, annot=True, cmap=\"BuPu\", fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "plt.title(\"NaiveBayes Classification\")\n",
    "sns.heatmap(mb_cm, cbar=False, annot=True, cmap=\"Greens\", fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "plt.title(\"SVM Classification\")\n",
    "sns.heatmap(svm_cm, cbar=False, annot=True, cmap=\"YlGnBu\",  fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "plt.title(\"ADABOOST Classification\")\n",
    "sns.heatmap(adaboost_cmatrix, cbar=False, annot=True, cmap=\"plasma\",  fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "plt.title(\"GRADIENT BOOSTING Classification\")\n",
    "sns.heatmap(gradientboost_cmatrix, cbar=False, annot=True, cmap=\"coolwarm\",  fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "plt.title(\"LIGHT GRADIENT BOOSTING Classification\")\n",
    "sns.heatmap(lgbm_cmatrix, cbar=False, annot=True, cmap=\"BuPu\",  fmt=\"d\")\n",
    "\n",
    "plt.subplot(3,3,9)\n",
    "plt.title(\"XGB Classification\")\n",
    "sns.heatmap(xgb_cmatrix, cbar=False, annot=True, cmap=\"YlGnBu\",  fmt=\"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bde883",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = {'Classifier' : ['LOGISTIC REGRESSION', 'DECISION TREE', 'RANDOM FOREST', 'MULTINOMIAL NAIVE BAYES', 'SUPPORT VECTOR MACHINE','Adaboost classifier','Gradient Boosting Classifier','XGB Classifier','Light Gradient Boosting classifier'], 'Accuracy_Score' : [accuracy_log, accuracy_dt, accuracy_rf, accuracy_mb, accuracy_svm,accuracy_ab,accuracy_gb,accuracy_xg,accuracy_lgbm], 'Precision_Score' : [precision_log, precision_dt, precision_rf, precision_mb, precision_svm,precision_ab,precision_gb,precision_xg,precision_lgbm], 'Recall_Score' : [recall_log, recall_dt, recall_rf, recall_mb, recall_svm,recall_ab,recall_gb,recall_xg,recall_lgbm], 'F1-Score' : [f1_log, f1_dt, f1_rf, f1_mb, f1_svm,f1_ab,f1_gb,f1_xg,f1_lgbm]}\n",
    "dataframe = pd.DataFrame(dataframe)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec73c58",
   "metadata": {},
   "source": [
    "## Accuracy comparison plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.style.use('ggplot')\n",
    "ax=sns.barplot(x=dataframe.Classifier,y=dataframe.Accuracy_Score,palette=sns.color_palette(\"Set2\"))\n",
    "ax.set_xticklabels(ax.get_xticklabels())\n",
    "plt.xlabel(\"Classification Models\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy scores of different classification models')\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.19,i.get_height()-0.3,\n",
    "           str(round((i.get_height()),4)), fontsize=15,color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73e759",
   "metadata": {},
   "source": [
    "## Finalizing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d78d84",
   "metadata": {},
   "source": [
    "### We finalize \"Light Gradient Boosting Classifier\" model as it gives 100% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5a4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
